{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import SyntheticData\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data=SyntheticData()\n",
    "\n",
    "\n",
    "def k(x, xprime):\n",
    "    with torch.no_grad():\n",
    "        v = torch.linalg.norm(x) * torch.linalg.norm(xprime)\n",
    "        u = .99999 * torch.dot(x, xprime) / v\n",
    "        return v * (u * (torch.pi - torch.arccos(u) + torch.sqrt(1 - u ** 2) )/ (2 * np.pi)\n",
    "                    +  u * (torch.pi - torch.arccos(u)) /  (2 * np.pi))\n",
    "\n",
    "def ntk_kernel(x,z):\n",
    "    n,_=x.shape\n",
    "    m,_=z.shape\n",
    "    H = torch.empty((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            H[i,j] = k(x[i], z[j])\n",
    "\n",
    "    return H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(u,v):\n",
    "    u=.99999*u\n",
    "    return v * (u * (torch.pi - torch.arccos(u) + torch.sqrt(1 - u ** 2) )/ (2 * np.pi)\n",
    "                    +  u * (torch.pi - torch.arccos(u)) /  (2 * np.pi))\n",
    "\n",
    "def kappa2(u):\n",
    "    u=.99999*u\n",
    "    return 2*u/torch.pi * (torch.pi - torch.arccos(u))  + torch.sqrt(1 - u ** 2) /torch.pi\n",
    "\n",
    "def easier_ntk(x,z):\n",
    "    inner_prod=x@z.T\n",
    "    norm_x=x.norm(dim=-1)\n",
    "    norm_z=z.norm(dim=-1)\n",
    "    norm_mat=norm_x.unsqueeze(1)@norm_z.unsqueeze(1).T\n",
    "\n",
    "    return kappa(inner_prod/norm_mat,norm_mat)\n",
    "\n",
    "def easier_ntk2(x,z):\n",
    "    inner_prod=x@z.T\n",
    "    norm_x=x.norm(dim=-1)\n",
    "    norm_z=z.norm(dim=-1)\n",
    "    norm_mat=norm_x.unsqueeze(1)@norm_z.unsqueeze(1).T\n",
    "\n",
    "    return norm_mat*kappa2(inner_prod/norm_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size :  200  Norm :  2.2862820625305176  Error test :  0.10999999999999999\n",
      "Training size :  1001  Norm :  5.871571063995361  Error test :  0.09999999999999998\n",
      "Training size :  2000  Norm :  9.110661506652832  Error test :  0.12\n",
      "Training size :  5000  Norm :  16.358280181884766  Error test :  0.09999999999999998\n",
      "Training size :  10000  Norm :  25.352684020996094  Error test :  0.10999999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "training_sizes = [200, 1001, 2000, 5000, 10000]\n",
    "for ntrain in training_sizes:\n",
    "\n",
    "    X_train,y_train=data.generate_synthetic_data_separable(ntrain,0.1)\n",
    "    X_test,y_test=data.generate_synthetic_data_separable(100,0.1)\n",
    "    #Kernel_train=ntk_kernel(X_train,X_train)\n",
    "    Kernel_train=easier_ntk2(X_train,X_train)\n",
    "    # Solve for alpha = K^-1 y\n",
    "    alpha_interp = torch.linalg.solve(Kernel_train, y_train)\n",
    "    #alpha_interp=torch.linalg.inv(Kernel_train)@y_train\n",
    "    # Compute RKHS norm for interpolated solution\n",
    "    rkhs_norm_interp = torch.sqrt((alpha_interp @ ( Kernel_train@ alpha_interp)))\n",
    "    rkhs_norm_interp = rkhs_norm_interp.item()\n",
    "\n",
    "\n",
    "    K_test_interp = easier_ntk2(X_train, X_test)\n",
    "    y_pred_interp = torch.sign(K_test_interp.T @ alpha_interp).squeeze()\n",
    "    error_interp = 1 - accuracy_score(y_test.cpu().numpy(), y_pred_interp.cpu().numpy())\n",
    "\n",
    "    print(\"Training size : \", ntrain, \" Norm : \",rkhs_norm_interp, \" Error test : \",error_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD time: 65.32s, top_q: 160, top_eigval: 94.75, new top_eigval: 1.03e-01\n",
      "n_subsamples=5000, bs_gpu=5000, eta=0.15, bs=64, top_eigval=9.48e+01, beta=415.98\n",
      "--------------------\n",
      "epoch:   0    time: 02.6s    train accuracy: 100.00%    val accuracy: 100.00%    train mse: nan    val mse: nan\n",
      "epoch:   2    time: 02.0s    train accuracy: 100.00%    val accuracy: 100.00%    train mse: nan    val mse: nan\n",
      "epoch:   4    time: 02.3s    train accuracy: 100.00%    val accuracy: 100.00%    train mse: nan    val mse: nan\n",
      "epoch:   6    time: 02.4s    train accuracy: 100.00%    val accuracy: 100.00%    train mse: nan    val mse: nan\n",
      "epoch:   8    time: 02.2s    train accuracy: 100.00%    val accuracy: 100.00%    train mse: nan    val mse: nan\n",
      "nan 0.10999999999999999\n"
     ]
    }
   ],
   "source": [
    "from eigenpro2.models import KernelModel\n",
    "kernel_fn = lambda x, y: easier_ntk2(x, y)\n",
    "\n",
    "X_train,y_train=data.generate_synthetic_data_separable(10000,0.0)\n",
    "X_test,y_test=data.generate_synthetic_data_separable(100,0.0)\n",
    "\n",
    "n_subsamples = min(len(X_train), 5000)\n",
    "top_q = min(160, n_subsamples - 1)\n",
    "\n",
    "model_overfit = KernelModel(kernel_fn, X_train, 1, device=torch.device(\"cpu\"))\n",
    "model_overfit.predict = lambda samples: model_overfit.forward(samples)\n",
    "\n",
    "try:\n",
    "        result_overfit = model_overfit.fit(\n",
    "            X_train, y_train.unsqueeze(1), X_test, y_test.unsqueeze(1),\n",
    "            n_subsamples=n_subsamples, epochs=10, mem_gb=8,\n",
    "            bs=64, top_q=top_q, print_every=2,run_epoch_eval=True)\n",
    "except:\n",
    "        result_overfit = model_overfit.fit(\n",
    "                X_train, y_train.unsqueeze(1), X_test, y_test.unsqueeze(1),\n",
    "                n_subsamples=n_subsamples, epochs=10, mem_gb=8,\n",
    "                bs=64, print_every=2,run_epoch_eval=True)\n",
    "        \n",
    "rkhs_norm_overfit = torch.norm(model_overfit.weight).item()\n",
    "\n",
    "# Predict and calculate classification error for overfitted\n",
    "y_pred_overfit = model_overfit.predict(X_test).sign().squeeze()\n",
    "error_overfit = 1 - accuracy_score(y_test.cpu().numpy(), y_pred_overfit.cpu().numpy())\n",
    "print(rkhs_norm_overfit,error_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_overfit.weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_overfit.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
