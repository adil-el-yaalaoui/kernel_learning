{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import SyntheticData\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data=SyntheticData()\n",
    "\n",
    "\n",
    "def k(x, xprime):\n",
    "    with torch.no_grad():\n",
    "        v = torch.linalg.norm(x) * torch.linalg.norm(xprime)\n",
    "        u = .99999 * torch.dot(x, xprime) / v\n",
    "        return v * (u * (torch.pi - torch.arccos(u) + torch.sqrt(1 - u ** 2) )/ (2 * np.pi)\n",
    "                    +  u * (torch.pi - torch.arccos(u)) /  (2 * np.pi))\n",
    "\n",
    "def ntk_kernel(x,z):\n",
    "    n,_=x.shape\n",
    "    m,_=z.shape\n",
    "    H = torch.empty((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            H[i,j] = k(x[i], z[j])\n",
    "\n",
    "    return H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(u,v):\n",
    "    u=.99999*u\n",
    "    return v * (u * (torch.pi - torch.arccos(u) + torch.sqrt(1 - u ** 2) )/ (2 * np.pi)\n",
    "                    +  u * (torch.pi - torch.arccos(u)) /  (2 * np.pi))\n",
    "\n",
    "def kappa2(u):\n",
    "    u=.99999*u\n",
    "    return 2*u/torch.pi * (torch.pi - torch.arccos(u))  + torch.sqrt(1 - u ** 2) /torch.pi\n",
    "\n",
    "def easier_ntk(x,z):\n",
    "    inner_prod=x@z.T\n",
    "    norm_x=x.norm(dim=-1)\n",
    "    norm_z=z.norm(dim=-1)\n",
    "    norm_mat=norm_x.unsqueeze(1)@norm_z.unsqueeze(1).T\n",
    "\n",
    "    return kappa(inner_prod/norm_mat,norm_mat)\n",
    "\n",
    "def easier_ntk2(x,z):\n",
    "    inner_prod=x@z.T\n",
    "    norm_x=x.norm(dim=-1)\n",
    "    norm_z=z.norm(dim=-1)\n",
    "    norm_mat=norm_x.unsqueeze(1)@norm_z.unsqueeze(1).T\n",
    "\n",
    "    return norm_mat*kappa2(inner_prod/norm_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size :  200  Norm :  3.206566333770752  Error test :  0.24\n",
      "Training size :  1001  Norm :  9.406493186950684  Error test :  0.32999999999999996\n",
      "Training size :  2000  Norm :  14.801255226135254  Error test :  0.29000000000000004\n",
      "Training size :  5000  Norm :  26.843603134155273  Error test :  0.29000000000000004\n",
      "Training size :  10000  Norm :  41.13756561279297  Error test :  0.19999999999999996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "training_sizes = [200, 1001, 2000, 5000, 10000]\n",
    "for ntrain in training_sizes:\n",
    "\n",
    "    X_train,y_train=data.generate_synthetic_data_non_separable(ntrain,0.1)\n",
    "    X_test,y_test=data.generate_synthetic_data_non_separable(100,0.1)\n",
    "    #Kernel_train=ntk_kernel(X_train,X_train)\n",
    "    Kernel_train=easier_ntk2(X_train,X_train)\n",
    "    # Solve for alpha = K^-1 y\n",
    "    alpha_interp = torch.linalg.solve(Kernel_train, y_train)\n",
    "    #alpha_interp=torch.linalg.inv(Kernel_train)@y_train\n",
    "    # Compute RKHS norm for interpolated solution\n",
    "    rkhs_norm_interp = torch.sqrt((alpha_interp @ ( Kernel_train@ alpha_interp)))\n",
    "    rkhs_norm_interp = rkhs_norm_interp.item()\n",
    "\n",
    "\n",
    "    K_test_interp = easier_ntk2(X_train, X_test)\n",
    "    y_pred_interp = torch.sign(K_test_interp.T @ alpha_interp).squeeze()\n",
    "    error_interp = 1 - accuracy_score(y_test.cpu().numpy(), y_pred_interp.cpu().numpy())\n",
    "\n",
    "    print(\"Training size : \", ntrain, \" Norm : \",rkhs_norm_interp, \" Error test : \",error_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 159 is out of bounds for dimension 0 with size 66",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m kernel_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: easier_ntk2(x, y)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m eigenpro2\u001b[38;5;241m.\u001b[39mKernelModel(kernel_fn, X_train, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem_gb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtop_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_q\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m coeff_kernel\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39msqueeze() \n\u001b[1;32m     16\u001b[0m kernel_train\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mkernel_matrix(X_train)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/eigenpro2/models.py:195\u001b[0m, in \u001b[0;36mKernelModel.fit\u001b[0;34m(self, x_train, y_train, x_val, y_val, epochs, mem_gb, print_every, n_subsamples, top_q, bs, eta, n_train_eval, run_epoch_eval, scale, seed, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m sample_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor(sample_ids, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    194\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenters[sample_ids]\n\u001b[0;32m--> 195\u001b[0m eigenpro_f, gap, top_eigval, beta \u001b[38;5;241m=\u001b[39m \u001b[43masm_eigenpro_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m new_top_eigval \u001b[38;5;241m=\u001b[39m top_eigval \u001b[38;5;241m/\u001b[39m gap\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/eigenpro2/models.py:53\u001b[0m, in \u001b[0;36masm_eigenpro_fn\u001b[0;34m(samples, map_fn, top_q, bs_gpu, alpha, min_q, seed)\u001b[0m\n\u001b[1;32m     50\u001b[0m     top_q \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum((eigvals)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m-\u001b[39malpha) \u001b[38;5;241m<\u001b[39m max_bs) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     51\u001b[0m     top_q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(top_q, min_q)\n\u001b[0;32m---> 53\u001b[0m eigvals, tail_eigval \u001b[38;5;241m=\u001b[39m eigvals[:top_q \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], \u001b[43meigvals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtop_q\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     54\u001b[0m eigvecs \u001b[38;5;241m=\u001b[39m eigvecs[:, :top_q \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     56\u001b[0m device \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mdevice\n",
      "\u001b[0;31mIndexError\u001b[0m: index 159 is out of bounds for dimension 0 with size 66"
     ]
    }
   ],
   "source": [
    "import eigenpro2\n",
    "X_train,y_train=data.generate_synthetic_data_non_separable(200,0)\n",
    "X_test,y_test=data.generate_synthetic_data_non_separable(100,0)\n",
    "\n",
    "n_subsamples = min(len(X_train), 5000)\n",
    "top_q = min(160, n_subsamples - 1)\n",
    "\n",
    "\n",
    "kernel_fn = lambda x, y: easier_ntk2(x, y)\n",
    "\n",
    "model = eigenpro2.KernelModel(kernel_fn, X_train, 1, device=torch.device(\"cpu\"))\n",
    "\n",
    "results = model.fit(X_train, y_train.unsqueeze(1), X_test, y_test.unsqueeze(1), epochs=20, print_every=2, mem_gb=8,top_q=top_q)\n",
    "\n",
    "coeff_kernel=model.weight.squeeze() \n",
    "kernel_train=model.kernel_matrix(X_train)\n",
    "\n",
    "rkhs_norm_overfit = torch.sqrt(coeff_kernel@(kernel_train@coeff_kernel))\n",
    "\n",
    "# Predict and calculate classification error for overfitted\n",
    "y_pred_overfit = model.forward(X_test).sign().squeeze()\n",
    "error_overfit = 1 - accuracy_score(y_test.cpu().numpy(), y_pred_overfit.cpu().numpy())\n",
    "print(rkhs_norm_overfit,error_overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
